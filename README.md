# Real Estate AI Agent

An intelligent agent for scraping and analyzing commercial real estate listings. This tool automatically collects property listings from specified websites and organizes them in Google Sheets.

## Features

- ğŸ¤– Automated web scraping of real estate listings
- ğŸ“Š Google Sheets integration for data storage and analysis
- â° Configurable scheduling (hourly/daily/weekly)
- ğŸ” Advanced filtering capabilities
- ğŸ“§ Email notifications for new listings
- ğŸŒ Support for multiple websites
- ğŸ“± Modern web interface for monitoring and configuration

## Setup

1. Clone the repository:
```bash
git clone https://github.com/mgilady99/REALESTEAIAGENT.git
cd REALESTEAIAGENT
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
- Copy `.env.example` to `.env`
- Update the variables with your configuration

5. Set up Google Sheets API:
- Create a Google Cloud Project
- Enable Google Sheets API
- Create service account and download credentials
- Save as `credentials.json` in project root
- Share target Google Sheet with service account email

## Configuration

### Website Configuration
Add your target websites in `config.py`:
```python
WEBSITES = {
    'website_name': {
        'url': 'https://example.com/commercial',
        'selectors': {
            'listings': '.property-listing',
            'title': '.property-title',
            'price': '.property-price',
            'size': '.property-size',
            'location': '.property-location',
            'type': '.property-type',
            'link': '.property-link'
        }
    }
}
```

### Search Criteria
Configure default search criteria in `config.py`:
```python
DEFAULT_CRITERIA = {
    'min_price': 0,
    'max_price': float('inf'),
    'min_size': 0,
    'max_size': float('inf'),
    'property_types': ['commercial', 'retail', 'office', 'industrial'],
    'locations': []
}
```

## Usage

1. Start the scraper:
```bash
python main.py
```

2. Monitor through web interface:
```bash
python app.py
```

Access the dashboard at `http://localhost:5000`

## Project Structure

```
REALESTEAIAGENT/
â”œâ”€â”€ app.py              # Web interface
â”œâ”€â”€ config.py           # Configuration settings
â”œâ”€â”€ scraper.py          # Main scraping logic
â”œâ”€â”€ sheets_handler.py   # Google Sheets integration
â”œâ”€â”€ models.py           # Database models
â”œâ”€â”€ utils.py           # Utility functions
â”œâ”€â”€ templates/         # Web interface templates
â”œâ”€â”€ static/           # Static files (CSS, JS)
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md         # Project documentation
```

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.
